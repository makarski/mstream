[[services]]
provider = "pubsub"
name = "pubsub-example"
auth = { kind = "service_account", account_key_path = "/path/to/service-account.json" }

[[services]]
provider = "pubsub"
name = "pubsub-static-token"
auth = { kind = "static_token", env_token_name = "PUBSUB_TOKEN" }

[[services]]
provider = "kafka"
name = "kafka-local"
"bootstrap.servers" = "localhost:9092"

[[services]]
provider = "kafka"
name = "kafka-cloud"
offset_seek_back_seconds = 3600 # Optional: Seek back 1h in time for Kafka source
"bootstrap.servers" = "your-kafka-broker:9092"
"security.protocol" = "SASL_SSL"
"sasl.mechanism" = "PLAIN"
"sasl.username" = "env:MSTREAM_KAFKA_USERNAME"
"sasl.password" = "env:MSTREAM_KAFKA_PASSWORD"
"client.id" = "mstream-client"
"group.id" = "mstream-group"

[[services]]
provider = "mongodb"
name = "mongodb-source"
connection_string = "mongodb://localhost:27017"
db_name = "example_db"
schema_collection = "test_schemas" # Optional: collection to store Avro schemas

[[services]]
provider = "http"
name = "http-local"
url = "http://localhost:8000/rustest"
max_retries = 5 # Optional: default is 5
base_backoff_ms = 1000 # Optional: default is 1000ms
connection_timeout_sec = 30
timeout_sec = 30 # Optional: default is 30 seconds
tcp_keepalive_sec = 300 # Optional: default is 300 seconds

# Connector Configurations
[[connectors]]
name = "mongodb-source-connector"
# Configure the source MongoDB collection to watch for changes
source = { service_name = "mongodb-source", id = "example_collection", encoding = "bson" }
# Schema is optional - if omitted, no field filtering will be applied
# schema = { service_name = "pubsub-example", id = "projects/your-project/schemas/example-schema", encoding = "avro" }
sinks = [
    { service_name = "kafka-local", id = "local_topic", encoding = "json" },
    { service_name = "kafka-cloud", id = "cloud_topic", encoding = "avro" },
    { service_name = "pubsub-example", id = "projects/your-project/topics/example-topic", encoding = "avro" },
    { service_name = "mongodb-source", id = "example_collection_copy", encoding = "bson" },
    { service_name = "http-local", id = "http_sink", encoding = "json" }
]

[[connectors]]
name = "basic-mongodb-connector"
# Simple configuration without schema filtering
source = { service_name = "mongodb-source", id = "simple_collection", encoding = "bson" }
# No schema defined - all fields will be passed through
sinks = [
    { service_name = "kafka-local", id = "unfiltered_topic", encoding = "json" }
]

[[connectors]]
name = "kafka-source-connector"
# Configure Kafka as a source
source = { service_name = "kafka-cloud", id = "source_topic", encoding = "avro" }
# Schema is optional for filtering fields
schema = { service_name = "pubsub-example", id = "projects/your-project/schemas/kafka-source-schema", encoding = "avro" }
sinks = [
    { service_name = "kafka-local", id = "processed_topic", encoding = "json" },
    { service_name = "pubsub-example", id = "projects/your-project/topics/processed-topic", encoding = "avro" },
]

[[connectors]]
name = "pubsub-source-connector"
# Configure PubSub as a source
source = { service_name = "pubsub-example", id = "projects/your-project/subscriptions/example-subscription", encoding = "avro" }
# Schema configuration is optional
# schema = { service_name = "mongodb-source", id = "example-id", encoding = "avro" }
sinks = [
    { service_name = "kafka-cloud", id = "pubsub_data_topic", encoding = "avro" },
    { service_name = "kafka-local", id = "pubsub_data_local", encoding = "json" },
]
